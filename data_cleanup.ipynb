{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required modules**\n",
    "* `requests` used for importing the downloaded zip file\n",
    "* `zipfile` for opening the zip file\n",
    "* `pandas` as datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing file and creating pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.31GB [1:15:14, 511kB/s] \n"
     ]
    }
   ],
   "source": [
    "#Download data to hospitalPriceData.zip in working directory\n",
    "hospitalPriceData_zip_url = 'https://www.dolthub.com/csv/dolthub/hospital-price-transparency-v3/iptu80riko4il5qij5asr8nalodeo9ut?include_bom=0'\n",
    "\n",
    "#session to efficiently use data streaming\n",
    "session = requests.Session()\n",
    "response = session.get(hospitalPriceData_zip_url, stream= True)\n",
    "total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "block_size = 1024**2 #1 MiB blockst\n",
    "progress_bar = tqdm(total= total_size_in_bytes, unit= 'B', unit_scale= True)\n",
    "with open(\"hospitalPriceData.zip\", \"wb\") as file:\n",
    "    for data in response.iter_content(block_size):\n",
    "        response.raise_for_status()\n",
    "        progress_bar.update(len(data))\n",
    "        file.write(data)\n",
    "progress_bar.close()\n",
    "\n",
    "#2.31 GB, TOOK 1hr 15min with 675mb ethernet (but dolthub was bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 40.6 s, total: 2min 9s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Extract files from hospitalPriceData.zip\n",
    "zf = zipfile.ZipFile('hospitalPriceData.zip')\n",
    "zf.extractall()\n",
    "\n",
    "#3min 18s wall time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'nginx', 'Date': 'Tue, 10 Oct 2023 01:20:56 GMT', 'Content-Type': 'application/octet-stream', 'Content-Length': '104857600', 'Last-Modified': 'Thu, 06 Jul 2023 13:01:32 GMT', 'Connection': 'keep-alive', 'ETag': '\"64a6bb2c-6400000\"', 'Accept-Ranges': 'bytes'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospitalPriceData_zip_url = 'https://proof.ovh.net/files/100Mb.dat'\n",
    "response = requests.head(hospitalPriceData_zip_url)\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gisco_id', 'lau_name', 'country', 'street_name', 'named_after_n',\n",
      "       'label', 'named_after_id', 'instance_of_label', 'person', 'description',\n",
      "       'gender', 'occupation_label', 'occupation_category', 'date_of_birth',\n",
      "       'date_of_death', 'place_of_birth_label', 'place_of_death_label',\n",
      "       'country_of_citizenship_label', 'place_of_birth_latitude',\n",
      "       'place_of_birth_longitude', 'place_of_death_latitude',\n",
      "       'place_of_death_longitude', 'wikipedia', 'picture_embed',\n",
      "       'image_credit'],\n",
      "      dtype='object')\n",
      "Index(['gisco_id', 'lau_name', 'country', 'street_name', 'named_after_n',\n",
      "       'label', 'named_after_id', 'instance_of_label', 'person', 'gender',\n",
      "       'occupation_label', 'occupation_category', 'date_of_birth',\n",
      "       'date_of_death', 'place_of_birth_label', 'place_of_death_label',\n",
      "       'country_of_citizenship_label', 'place_of_birth_latitude',\n",
      "       'place_of_birth_longitude', 'place_of_death_latitude',\n",
      "       'place_of_death_longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "streetname_df = pd.read_csv('all_data_mapping_diversity/allstreets_allcities_aug-23.csv')\n",
    "print(streetname_df.columns)\n",
    "streetname_df_CUT = streetname_df.drop(['description', \n",
    "                                        'wikipedia', \n",
    "                                        'picture_embed', \n",
    "                                        'image_credit'], axis='columns')\n",
    "print(streetname_df_CUT.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gisco_id lau_name country         street_name  named_after_n label  \\\n",
      "0  AT_90001     Wien      AT         \"Am Wasser\"            1.0   NaN   \n",
      "1  AT_90001     Wien      AT                   1            1.0   NaN   \n",
      "2  AT_90001     Wien      AT  1. Haidequerstraße            1.0   NaN   \n",
      "3  AT_90001     Wien      AT       1. Molostraße            1.0   NaN   \n",
      "4  AT_90001     Wien      AT           1. Straße            1.0   NaN   \n",
      "\n",
      "  named_after_id instance_of_label  person gender  ... occupation_category  \\\n",
      "0            NaN               NaN     0.0    NaN  ...                 NaN   \n",
      "1            NaN               NaN     0.0    NaN  ...                 NaN   \n",
      "2            NaN               NaN     0.0    NaN  ...                 NaN   \n",
      "3            NaN               NaN     0.0    NaN  ...                 NaN   \n",
      "4            NaN               NaN     0.0    NaN  ...                 NaN   \n",
      "\n",
      "  date_of_birth date_of_death place_of_birth_label place_of_death_label  \\\n",
      "0           NaN           NaN                  NaN                  NaN   \n",
      "1           NaN           NaN                  NaN                  NaN   \n",
      "2           NaN           NaN                  NaN                  NaN   \n",
      "3           NaN           NaN                  NaN                  NaN   \n",
      "4           NaN           NaN                  NaN                  NaN   \n",
      "\n",
      "  country_of_citizenship_label place_of_birth_latitude  \\\n",
      "0                          NaN                     NaN   \n",
      "1                          NaN                     NaN   \n",
      "2                          NaN                     NaN   \n",
      "3                          NaN                     NaN   \n",
      "4                          NaN                     NaN   \n",
      "\n",
      "   place_of_birth_longitude  place_of_death_latitude  place_of_death_longitude  \n",
      "0                       NaN                      NaN                       NaN  \n",
      "1                       NaN                      NaN                       NaN  \n",
      "2                       NaN                      NaN                       NaN  \n",
      "3                       NaN                      NaN                       NaN  \n",
      "4                       NaN                      NaN                       NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(streetname_df_CUT.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,\n",
       "       'culture, science, arts; culture, science, arts; culture, science, arts; politics and government',\n",
       "       'culture, science, arts; culture, science, arts; culture, science, arts',\n",
       "       ...,\n",
       "       'culture, science, arts; culture, science, arts; culture, science, arts; politics and government; culture, science, arts; culture, science, arts; politics and government; culture, science, arts',\n",
       "       'culture, science, arts; culture, science, arts; culture, science, arts; culture, science, arts; culture, science, arts; politics and government; politics and government',\n",
       "       'culture, science, arts; culture, science, arts; culture, science, arts; culture, science, arts; military; culture, science, arts'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streetname_df_CUT.occupation_category.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
